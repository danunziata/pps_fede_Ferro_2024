{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Practicas Profesionales - Federico Rodriguez Ferro","text":"<p>En un mundo cada vez m\u00e1s digitalizado, la seguridad de las infraestructuras tecnol\u00f3gicas se vuelve fundamental para garantizar el correcto funcionamiento de las operaciones empresariales. En este sentido, los entornos de contenedores, como Kubernetes, han emergido como una soluci\u00f3n popular para gestionar aplicaciones en entornos distribuidos. Sin embargo, junto con su adopci\u00f3n, surgen desaf\u00edos relacionados con la seguridad y privacidad de los datos.</p> <p>Por lo tanto, se vuelve imperativo mejorar la seguridad y privacidad del entorno productivo del cl\u00faster de Kubernetes. Esto implica la implementaci\u00f3n de medidas efectivas que mitiguen posibles riesgos de seguridad, salvaguardando as\u00ed la integridad de los sistemas y la confidencialidad de los datos en todo momento. Para alcanzar este objetivo, se plantean una serie de objetivos espec\u00edficos que abarcan desde la comprensi\u00f3n de los fundamentos de Kubernetes hasta la evaluaci\u00f3n de soluciones de monitoreo y detecci\u00f3n de intrusiones, con el fin de promover un entorno seguro y confiable para las operaciones en el cl\u00faster de Kubernetes.</p>"},{"location":"#objetivos-generales","title":"Objetivos Generales","text":"<p>Mejorar la seguridad y privacidad del entorno productivo del cl\u00faster de Kubernetes que utiliza el GCID (Gestor de Contenedores de Infraestructura Distribuida). Se busca implementar medidas efectivas que fortalezcan la infraestructura y mitiguen posibles riesgos de seguridad, salvaguardando as\u00ed la integridad de los sistemas y la confidencialidad de los datos en todo momento. Esta mejora se llevar\u00e1 a cabo mediante la implementaci\u00f3n de pol\u00edticas, procedimientos y herramientas adecuadas que promuevan un entorno seguro y confiable para las operaciones en el cl\u00faster de Kubernetes.</p>"},{"location":"#objetivos-especificos","title":"Objetivos Especificos","text":"<ul> <li>Familiarizarse con la tecnolog\u00eda de contenedores y comprender los fundamentos de Kubernetes en entornos seguros.</li> <li>Investigar y profundizar en herramientas de seguridad aplicadas al desarrollo de aplicaciones en entornos de contenedores.</li> <li>Desplegar un cl\u00faster de Kubernetes y configurarlo correctamente.</li> <li>Identificar y aplicar medidas de seguridad necesarias, como autenticaci\u00f3n, autorizaci\u00f3n, cifrado y pol\u00edticas de acceso.</li> <li>Evaluar y seleccionar soluciones de monitoreo y detecci\u00f3n de intrusiones para el cl\u00faster de Kubernetes.</li> <li>Realizar pruebas de penetraci\u00f3n y evaluaci\u00f3n de vulnerabilidades para identificar posibles puntos d\u00e9biles en el cl\u00faster.</li> <li>Documentar las configuraciones y medidas de seguridad implementadas.</li> </ul>"},{"location":"contexto/","title":"Introducci\u00f3n","text":"<p>La documentaci\u00f3n aborda aspectos cruciales en el desarrollo y la seguridad de aplicaciones modernas, destacando la integraci\u00f3n de la seguridad en el ciclo de vida del desarrollo y la importancia de la observabilidad y Kubernetes en este proceso.</p>"},{"location":"contexto/#devsecops","title":"DevSecOps","text":"<p>Vendr\u00eda a ser como un triangulo que esta compuesto por: el desarrollo, la seguridad y las operaciones. El objetivo es integrar la seguridad en nuestro CI/CD ya sea en preproduccion o produccion.</p> <p></p> <p>DevOps gano importancia en los ultimos a\u00f1os ya que combina principios clave de las operaciones con los ciclos de desarrollo.</p> <p>La seguridad refiere a todas las herramientas y tecnicas necesarias para dise\u00f1ar y construir una aplicacion capaz de resistir ataques, capaz de detectarlos y responder a ellas lo mas rapido posibles. Agregando la seguridad a DevOps, desde el inicio del dise\u00f1o hasta la eventual implementacion, las distintas organizaciones pueden alinear estos tres componentes fundamientales en la creacion y entrega de software.</p> <p>DevSecOps permite que las pruebas de seguridad ocurran al mismo tiempo que otros desarrollos o testeos se encuentren en marcha.</p> <p></p> <p>El primer desaf\u00edo implica capacitar a los equipos de DevOps en seguridad y promover una cultura de responsabilidad sobre la seguridad del software. El segundo desaf\u00edo es encontrar y integrar herramientas de  seguridad adecuadas en el flujo de trabajo de DevOps. La automatizaci\u00f3n  es clave, pero las herramientas tradicionales pueden no ser suficientes  debido a cambios en el entorno de desarrollo, como el aumento del  software de c\u00f3digo abierto y las aplicaciones en contenedores.</p>"},{"location":"contexto/#observabilidad","title":"Observabilidad","text":"<p>La observabilidad se refiere a c\u00f3mo se puede comprender el  estado interno de un sistema mediante el examen de sus salidas externas, en especial, sus datos.</p> <p>En el contexto del desarrollo de aplicaciones modernas, la  observabilidad hace referencia a la recopilaci\u00f3n y el an\u00e1lisis de datos  (logs, m\u00e9tricas y rastreos) de una gran variedad de fuentes, con el  objetivo de brindar informaci\u00f3n detallada sobre el comportamiento de las aplicaciones que se ejecutan en tus entornos. Se puede aplicar a  cualquier sistema que compiles y desees monitorear. </p> <p>Esto se hace con la ayuda de visualizaciones (dashboards, mapas de  dependencias de servicios y rastreos distribuidos), as\u00ed como con  enfoques de AIOps y machine learning. Con la soluci\u00f3n de observabilidad  adecuada, puedes comprender el rendimiento de tus aplicaciones,  servicios e infraestructura para rastrear problemas y responder a ellos.</p> <p>La observabilidad es importante porque permite a los equipos evaluar,  monitorear y mejorar el rendimiento de sistemas de IT distribuidos. Es  mucho m\u00e1s efectiva que los m\u00e9todos de monitoreo tradicionales. Una  plataforma de observabilidad integral puede ayudar a desarmar silos y  fomentar la colaboraci\u00f3n. Los problemas pueden diagnosticarse,  analizarse y rastrarse hasta sus or\u00edgenes de forma proactiva. </p> <p>Los tres pilares de la observabilidad son los logs, las m\u00e9tricas y los rastreos. La observabilidad del stack completo te permite rastrear el rendimiento de tu ecosistema multicloud hist\u00f3rico y en tiempo real. </p> <p>La observabilidad lleva a una entrega de aplicaciones m\u00e1s r\u00e1pida y de  mayor calidad, lo que significa ahorro de costos y optimizaci\u00f3n de  recursos para tus equipos. Las aplicaciones con mejor rendimiento  llevan, en \u00faltima instancia, a m\u00e1s ingresos.</p>"},{"location":"contexto/#kubernetes","title":"Kubernetes","text":"<p>Kubernetes es una plataforma portable y extensible de c\u00f3digo abierto para administrar cargas de trabajo y servicios. Kubernetes facilita la automatizaci\u00f3n y la configuraci\u00f3n declarativa. Tiene un ecosistema grande y en r\u00e1pido crecimiento. El soporte, las herramientas y los servicios para Kubernetes est\u00e1n ampliamente disponibles.</p> <p>Kubernetes ofrece un entorno de administraci\u00f3n centrado en contenedores. Kubernetes orquesta la infraestructura de c\u00f3mputo, redes y almacenamiento para que las cargas de trabajo de los usuarios no tengan que hacerlo. Esto ofrece la simplicidad de las Plataformas como Servicio (PaaS) con la flexibilidad de la Infraestructura como Servicio (IaaS) y permite la portabilidad entre proveedores de infraestructura.</p> <p>A pesar de que Kubernetes ya ofrece muchas funcionalidades, siempre hay nuevos escenarios que se benefician de nuevas caracter\u00edsticas. Los flujos de trabajo de las aplicaciones pueden optimizarse para acelerar el tiempo de desarrollo. Una soluci\u00f3n de orquestaci\u00f3n propia puede ser suficiente al principio, pero suele requerir una automatizaci\u00f3n robusta cuando necesita escalar. Es por ello que Kubernetes fue dise\u00f1ada como una plataforma: para poder construir un ecosistema de componentes y herramientas que hacen m\u00e1s f\u00e1cil el desplegar, escalar y administrar aplicaciones.</p> <p>Las etiquetas, o Labels, le permiten a los usuarios organizar sus recursos como deseen. Las anotaciones, o Annotations, les permiten asignar informaci\u00f3n arbitraria a un recurso para facilitar sus flujos de trabajo y hacer m\u00e1s f\u00e1cil a las herramientas administrativas inspeccionar el estado.</p> <p>Adem\u00e1s, el Plano de Control de Kubernetes usa las mismas APIs que usan los desarrolladores y usuarios finales. Los usuarios pueden escribir sus propios controladores, como por ejemplo un planificador o scheduler, usando sus propias APIs desde una herramienta de l\u00ednea de comandos.</p> <p>Este dise\u00f1o ha permitido que otros sistemas sean construidos sobre Kubernetes.</p> <p>Cuando se despliega Kubernetes, obtenemos un Cluster. Consiste en un grupo de workers, llamados nodos, que corren aplicaciones en contenedores. Cada Cluster tiene un nodo m\u00ednimo.</p> <p>Los nodos workers alojan los Pods que son los componentes de la  carga de trabajo de la aplicaci\u00f3n. El plano de control gestiona los nodos de trabajadores y los Pods en el cl\u00faster. En entornos de producci\u00f3n, el plano de control generalmente se ejecuta en m\u00faltiples computadoras y un Cl\u00faster generalmente ejecuta m\u00faltiples nodos,  proporcionando tolerancia a fallos y alta disponibilidad.</p> <p></p>"},{"location":"contexto/#diferentes-areas-de-aplicacion-de-seguridad-en-kubernetes","title":"Diferentes \u00e1reas de aplicaci\u00f3n de seguridad en Kubernetes","text":""},{"location":"contexto/#configuracion-de-seguridad-en-el-cluster","title":"Configuraci\u00f3n de Seguridad en el Cluster","text":"<ul> <li> <p>Permisos y controles de acceso</p> </li> <li> <p>Seguridad para el servidor API</p> </li> <li> <p>Auditar configuracion del cluster</p> </li> <li> <p>Pol\u00edticas de seguridad de los PODS</p> </li> <li> <p>Pol\u00edticas de red</p> </li> <li> <p>Requerimientos regulatorios</p> </li> </ul>"},{"location":"contexto/#manejo-de-identidad-y-acceso","title":"Manejo de Identidad y Acceso","text":"<ul> <li>M\u00e9todos de autentificaci\u00f3n seguros</li> <li>Acceso de control basado en la implementacion de roles</li> <li>Utilizaci\u00f3n de recursos</li> <li>Monitorear al usuario</li> <li>Asegurar al acceso al panel de control</li> <li>Proteger las credenciales</li> <li>Segmentaci\u00f3n de redes para isolar los nodos y los pods del publico</li> <li>Monitorear anomal\u00edas</li> </ul>"},{"location":"contexto/#seguridad-de-red","title":"Seguridad de red","text":"<ul> <li>Segmentaci\u00f3n e Isolaci\u00f3n de la red</li> <li>Pol\u00edticas de red</li> <li>Herramientas de seguridad de red</li> <li>Encriptaci\u00f3n de datos</li> <li>Canales seguros de comunicacion</li> <li>Habitar la encriptacion SSL/TLS</li> <li>Ocultar los metadata de los kubernetes</li> <li>Deshabilitar servicios innecesarios</li> <li>Monitoreo de trafico</li> <li>Implementar procedimientos de respuesta </li> </ul>"},{"location":"contexto/#seguridad-del-nodo","title":"Seguridad del Nodo","text":"<ul> <li>Seguridad del sistema operativo</li> <li>Seguridad de la red</li> <li>Seguridad del nodo</li> <li>Seguridad de los containers</li> <li>Seguridad de los contenedores de imaganes</li> </ul>"},{"location":"contexto/#seguridad-del-pod","title":"Seguridad del Pod","text":"<ul> <li>Seguridad de los kubernetes </li> <li>Usar contenedores seguros</li> <li>Principios menos priviligiados</li> <li>Montar volumenes seguros</li> <li>Utilizar variables de ambiente seguras</li> <li>Actividad del Pod</li> <li>Control de Acceso</li> </ul>"},{"location":"contexto/#seguridad-de-la-imagen","title":"Seguridad de la imagen","text":"<ul> <li>Registros del contenedor</li> <li>Escaneo de la imagen</li> <li>Actualizaciones</li> </ul>"},{"location":"contexto/#administracion-de-secrets","title":"Administraci\u00f3n de Secrets","text":"<ul> <li>Evitar la exposicion de secrets</li> <li>Encriptaci\u00f3n y Administraci\u00f3n de secrets</li> </ul>"},{"location":"contexto/#monitoreo","title":"Monitoreo","text":"<ul> <li>Plataforma de Registros</li> <li>Auditaje</li> <li>Notificaciones y Alertas</li> </ul>"},{"location":"contexto/#recuperacion-de-respaldo","title":"Recuperaci\u00f3n de Respaldo","text":"<ul> <li>Almacenamiento de Datos</li> <li>Procesos de restauraci\u00f3n</li> <li>Plan de contingencia</li> </ul>"},{"location":"instalacion/","title":"Instalaci\u00f3n","text":"<p>En este documento, desarrollaremos dos entornos totalmente diferentes que pueden ser utilizados para replicar el cl\u00faster en el que trabajaremos, de una forma m\u00e1s liviana y que pueda ser soportada por nuestra m\u00e1quina personal.</p> <p>El primer entorno de desarrollo estar\u00e1 centrado en replicar el cl\u00faster de una forma liviana, permitiendo que nuestra m\u00e1quina personal pueda soportarlo sin problemas. En este caso utilizaremos minikube que es una de las herramientas mas facil de implementar y utilizar a la hora de hacer nuestro primer acercamiento a Kubernetes</p> <p>El segundo entorno de laboratorio se configurar\u00e1 utilizando KVM y Multipass, dise\u00f1ado espec\u00edficamente para instalar Kubernetes utilizando la tecnolog\u00eda k3s. Este m\u00e9todo proporciona una soluci\u00f3n eficiente y manejable para desplegar Kubernetes en un entorno de virtualizaci\u00f3n. Tiene una mejor aproximacion a las implementaciones reales.</p>"},{"location":"instalacion/#prerequesitos","title":"Prerequesitos","text":""},{"location":"instalacion/#zsh","title":"ZSH","text":"<p>zsh es un int\u00e9rprete de comandos de Unix que ofrece funcionalidades avanzadas en comparaci\u00f3n con otros shells comunes, como Bash (Bourne Again Shell). Zsh incluye caracter\u00edsticas como completado de comandos m\u00e1s robusto, expansi\u00f3n de nombres de archivo mejorada, temas y personalizaci\u00f3n m\u00e1s avanzada, correcci\u00f3n ortogr\u00e1fica integrada, entre otras. Es altamente configurable y es utilizado por muchos usuarios  avanzados y desarrolladores como su shell predeterminado debido a su  potencia y flexibilidad.</p> <p>Para Instalarlo simplemente ejecutamos la siguiente linea en nuestra terminal</p> <pre><code>sudo apt-get install zsh\n</code></pre> <p>Para ejecutarlo</p> <pre><code>zsh\n</code></pre> <p>En caso de que se quiera personalizar el shell se puede descargar el framework Oh My Zsh con el siguiente comando</p> <pre><code>sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n</code></pre> <p>Toda la documentaci\u00f3n acerca de ohmyzsh se encuentra en la wiki.</p>"},{"location":"instalacion/#kvm","title":"KVM","text":"<p>Las m\u00e1quinas virtuales basadas en el kernel (KVM) son una tecnolog\u00eda de virtualizaci\u00f3nopen source integrada a Linux\u00ae. Con ellas, puede transformar Linux en un hipervisor que permite que una m\u00e1quina host ejecute varios entornos virtuales aislados llamados m\u00e1quinas virtuales (VM) o guests. </p> <p>Las KVM convierten Linux en un hipervisor de tipo 1. Todos los hipervisores necesitan algunos elementos del sistema operativo (por ejemplo, el administrador de memoria, el programador de procesos, la stack de entrada o salida [E/S], los controladores de dispositivos, el administrador de seguridad y la stack de red, entre otros) para ejecutar las m\u00e1quinas virtuales. Las KVM tienen todos estos elementos porque forman parte del kernel de Linux. Cada m\u00e1quina virtual se implementa como un proceso habitual de Linux, el cual se programa con la herramienta est\u00e1ndar de Linux para este fin, e incluye sistemas virtuales de hardware exclusivos, como la tarjeta de red, el adaptador gr\u00e1fico, las CPU, la memoria y los discos.</p> <p>Instalaci\u00f3n</p> <pre><code>sudo apt update\nsudo apt install cpu-checker\nkvm-ok                                                                   # Comprueba si la virtualizacion esta habilitada\nsudo apt install qemu-kvm libvirt-bin bridge-utils virtinst virt-manager # Instala las librerias necesarias\nsudo usermod -aG kvm,libvirt $USER                                       # Agrupa un par de grupos a un usuario\nsudo systemctl is-active libvirtd                                        # \"active\" si esta todo activado\n</code></pre>"},{"location":"instalacion/#kubectl","title":"Kubectl","text":"<p>Es una herramienta de l\u00ednea de comandos de Kubernetes para desplegar y gestionar aplicaciones en Kubernetes. Usando kubectl, puedes inspeccionar recursos del cl\u00faster; crear, eliminar, y actualizar  componentes; explorar tu nuevo cl\u00faster y arrancar aplicaciones.</p> <p>Instalaci\u00f3n</p> <p>Descargar la ultima version</p> <pre><code>curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n</code></pre> <p>Instalarlo</p> <pre><code>sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n</code></pre> <p>Comprobar que se ha instalado de manera correcta</p> <pre><code>kubectl version --client\n</code></pre>"},{"location":"instalacion/#desarrollo","title":"Desarrollo","text":"<p>Minikube es una herramienta de c\u00f3digo abierto que facilita la creaci\u00f3n y ejecuci\u00f3n de cl\u00fasteres de Kubernetes localmente en una m\u00e1quina individual. En un sentido t\u00e9cnico, Minikube utiliza una m\u00e1quina virtual para crear un entorno de cl\u00faster de Kubernetes que se ejecuta en una sola instancia de host. Utiliza tecnolog\u00edas como Docker y KVM (Kernel-based Virtual Machine) para emular un entorno de m\u00faltiples nodos Kubernetes en una sola m\u00e1quina f\u00edsica, lo que permite a los desarrolladores experimentar, probar y desarrollar aplicaciones Kubernetes sin necesidad de un entorno de producci\u00f3n completo. Minikube proporciona una forma r\u00e1pida y conveniente de familiarizarse con Kubernetes y probar aplicaciones en un entorno de desarrollo local antes de implementarlas en un cl\u00faster de producci\u00f3n.</p>"},{"location":"instalacion/#instalacion_1","title":"Instalaci\u00f3n","text":"<pre><code>curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube &amp;&amp; rm minikube-linux-amd64\n</code></pre>"},{"location":"instalacion/#creacion-de-cluster","title":"Creacion de Cluster","text":"<p>Para comenzar, iniciaremos arrancando el cluster teniendo en cuenta los par\u00e1metros que queremos que cumpla. Para ello, propondremos la siguiente linea de comando</p> <pre><code>minikube start --driver=kvm2 --nodes=\"Cantidad de nodos\" --memory=\"Cantidad de Memoria\" --cpu=\"Cantidad de cpu\"\n</code></pre> <p>A partir de aqui, nosotros podemos empezar a experimentar con la creacion de Pods que sean capaces de alojar nuestras aplicaciones.</p> <p>Un Pod es un grupo de uno o m\u00e1s contenedores, con almacenamiento/red compartidos, y unas especificaciones de c\u00f3mo ejecutar los contenedores. Los contenidos de un Pod son siempre coubicados, coprogramados y ejecutados en un contexto compartido. Un Pod modela un \"host l\u00f3gico\" espec\u00edfico de la aplicaci\u00f3n: contiene uno o m\u00e1s contenedores de aplicaciones relativamente entrelazados. Antes de la llegada de los contenedores, ejecutarse en la misma m\u00e1quina f\u00edsica o virtual significaba ser ejecutado en el mismo host l\u00f3gico.</p>"},{"location":"instalacion/#despliegue-de-una-aplicacion-python","title":"Despliegue de una aplicaci\u00f3n Python","text":"<p>Para concluir con este entorno de laboratorio, desplegaremos una aplicacion web programada en python como es Flask para hacer uso de todo el conocimiento que vimos en este documento.</p> <p>Empezaremos creando un Cluster simple de 2 nodos utilizando KVM, por el momento dejaremos el uso de nucleos y de RAM por defecto</p> <pre><code>minikube start --driver=kvm2 --nodes=2\n</code></pre> <p>Comprobamos que los nodos han sido habilitados de manera correcta</p> <pre><code>kubectl get nodes\n</code></pre> <p>Para correr la aplicacion utilizaremos el siguiente archivo deployment.yaml que cuenta con todo lo que necesitamos para ejecutar la aplicacion</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-python-service\nspec:\n  selector:\n    app: hello-python\n  ports:\n  - protocol: \"TCP\"\n    port: 6000\n    targetPort: 5000\n  type: LoadBalancer\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-python\nspec:\n  selector:\n    matchLabels:\n      app: hello-python\n  replicas: 4\n  template:\n    metadata:\n      labels:\n        app: hello-python\n    spec:\n      containers:\n      - name: hello-python\n        image: hello-python:latest\n        imagePullPolicy: Never\n        ports:\n        - containerPort: 5000\n</code></pre> <p>Como se observa en este script, se estan aplicando 2 caracteristicas que distinguen a los Kubernetes:</p> <ul> <li>Servicio LoadBalancer: es la forma est\u00e1ndar de exponer un servicio a Internet. Si se desea exponer directamente un servicio, este es el m\u00e9todo  predeterminado. Todo el tr\u00e1fico en el puerto que especifique se reenviar\u00e1 al servicio. No hay filtrado, ni enrutamiento, etc. Esto  significa que puedes enviarle casi cualquier tipo de tr\u00e1fico, como HTTP, TCP, UDP, Websockets, gRPC o lo que sea. En este caso se le expone el puerto 5000 para que pueda ser accedido de forma local por el puerto 6000.</li> <li>Deployment: se refiere a un objeto que describe c\u00f3mo se debe implementar y actualizar una aplicaci\u00f3n en el cl\u00faster. Proporciona un enfoque declarativo para definir el estado deseado de la aplicaci\u00f3n y permite que Kubernetes se encargue de llevar el estado actual al estado deseado de manera eficiente y confiable. Simplifica el proceso de despliegue y actualizaci\u00f3n de aplicaciones, proporcionando una forma estandarizada y automatizada de administrar el ciclo de vida de las aplicaciones en un cl\u00faster. En este caso se hace uso de una imagen que contiene lo necesario para correr la aplicacion y ademas se crean 4 replicas, es decir que 4 pods tendran esta aplicacion.</li> </ul> <p>Aplicamos el archivo con kubectl para que el cluster los ponga en marcha</p> <pre><code>kubectl apply -f deployment.yaml\n</code></pre> <p>Y listo, podemos comprar que nuestros pods estan funcionando con la aplicacion con el comando</p> <pre><code>kubectl get pods\n</code></pre> <p>Podemos entrar a la aplicacion a traves de http://localhost:6000 o podemos consultar la ip que tiene el minikube con</p> <pre><code>minikube ip\n</code></pre> <p>De esta manera, podemos probar nuestras aplicaciones de forma local para luego mandarlas posteriormente a produccion.</p>"},{"location":"instalacion/#laboratorio","title":"Laboratorio","text":""},{"location":"instalacion/#multipass","title":"Multipass","text":"<p>Multipass es un gestor de m\u00e1quinas virtuales (VM) ligero para Linux, Windows y macOS. Est\u00e1 dise\u00f1ado para desarrolladores que desean un entorno Ubuntu fresco con un solo comando. Utiliza KVM en Linux, Hyper-V en Windows y QEMU en macOS para ejecutar la VM con una sobrecarga m\u00ednima. Tambi\u00e9n puede usar VirtualBox en Windows y macOS. Multipass obtendr\u00e1 las im\u00e1genes por ti y las mantendr\u00e1 actualizadas.</p> <p>Dado que admite metadatos para cloud-init, puedes simular un peque\u00f1o despliegue en la nube en tu laptop o estaci\u00f3n de trabajo.</p> <p>Instalaci\u00f3n</p> <pre><code>sudo apt update\nsudo apt install snapd\nsudo snap install multipass\n</code></pre>"},{"location":"instalacion/#creacion-de-instancias","title":"Creaci\u00f3n de Instancias","text":"<p>Los nodos en Kubernetes son simplemente m\u00e1quinas virtuales que trabajan en sincronizaci\u00f3n. Para nuestro cl\u00faster, crearemos 3 m\u00e1quinas virtuales, cada una con 2 CPU, 2 GB de RAM y 4 GB de almacenamiento.</p>"},{"location":"instalacion/#claves-ssh","title":"Claves SSH","text":"<p>Crea una clave privada/p\u00fablica con el siguiente comando:</p> <pre><code>ssh-keygen\n</code></pre> <p>Esto crear\u00e1 los archivos mencionados anteriormente en tu sistema. Copia el contenido de <code>~/.ssh/id_rsa.pub</code> con:</p> <pre><code>cat ~/.ssh/id_rsa.pub\n</code></pre>"},{"location":"instalacion/#creando-el-archivo-de-configuracion","title":"Creando el archivo de configuraci\u00f3n","text":"<p>Crea un archivo llamado <code>multipass.yaml</code> y coloca tu clave p\u00fablica en <code>ssh-rsa</code>.</p> <p>multipass.yaml</p> <pre><code>yaml\nssh_authorized_keys:\n  - ssh-rsa &lt;a\u00f1ade-tu-clave-p\u00fablica&gt;\n</code></pre> <p>Este archivo de configuraci\u00f3n asegura que la clave p\u00fablica se almacene en la m\u00e1quina virtual una vez creada. Crearemos nuestras m\u00e1quinas virtuales con nombres adecuados basados en los roles que les asignaremos (master/worker).</p>"},{"location":"instalacion/#inicializacion","title":"Inicializaci\u00f3n","text":"<pre><code>multipass launch jammy --cpus 2 --mem 2G --disk 4G --name master-node --cloud-init multipass.yaml\nmultipass launch jammy --cpus 2 --mem 2G --disk 4G --name agent-worker --cloud-init multipass.yaml\n</code></pre> <p>En t\u00e9rminos de K3s, un nodo maestro se llama \"server\" y el resto de los nodos se llaman \"agents\". Los agentes son simplemente los nodos que se a\u00f1aden al nodo maestro; pueden ser otro nodo maestro o un nodo trabajador.</p>"},{"location":"instalacion/#k3sup","title":"k3sup","text":"<p>k3sup es una utilidad ligera para pasar de cero a KUBECONFIG con k3s en cualquier m\u00e1quina virtual local o remota. Todo lo que necesitas es acceso SSH y el binario de k3sup para obtener acceso a kubectl de inmediato.</p> <p>Esta herramienta utiliza SSH para instalar k3s en un host Linux remoto. Tambi\u00e9n puedes usarla para unir hosts Linux existentes a un cl\u00faster k3s como agentes. Primero, k3s se instala utilizando el script de utilidad de Rancher, junto con una flag para la IP p\u00fablica de tu host para que TLS funcione correctamente. Luego, se obtiene y actualiza el archivo kubeconfig en el servidor para que puedas conectarte desde tu laptop usando kubectl.</p> <p>k3sup se desarroll\u00f3 para automatizar lo que puede ser un proceso muy manual y confuso para muchos desarrolladores, que ya est\u00e1n cortos de tiempo. Una vez que has provisionado una VM con tu herramienta favorita, k3sup significa que solo est\u00e1s a 60 segundos de ejecutar <code>kubectl get pods</code> en tu propia computadora. Si est\u00e1s en una computadora local, puedes omitir SSH con <code>k3sup install --local</code>.</p>"},{"location":"instalacion/#instalacion_2","title":"Instalaci\u00f3n","text":"<pre><code>curl -sLS https://get.k3sup.dev | sh\nsudo install k3sup /usr/local/bin/\n</code></pre>"},{"location":"instalacion/#anadiendo-nodos-con-k3sup","title":"A\u00f1adiendo nodos con k3sup","text":"<p>Ahora que tenemos nuestras VMs listas, instalemos Kubernetes en ellas. Primero, crearemos un nodo maestro para configurar un plano de control.</p>"},{"location":"instalacion/#nodo-maestro","title":"Nodo maestro","text":"<p>Necesitaremos la IP y el nombre de usuario de nuestra m\u00e1quina virtual para conectarnos por SSH e instalar Kubernetes. Ejecuta <code>multipass ls</code> y toma nota de la IP del <code>master-node</code>. Todos los nombres de usuario para las VMs son <code>ubuntu</code> por defecto.</p> <pre><code>k3sup install --ip &lt;IP&gt; --user ubuntu --k3s-extra-args \"--cluster-init\"\nexport KUBECONFIG=&lt;kubeconfig path&gt;\n</code></pre> <p>Pasamos <code>--k3s-extra-args \"--cluster-init\"</code> para asegurarnos de que este nodo est\u00e9 preparado para conectarse con otro nodo maestro, de lo contrario, podr\u00eda causar errores.</p> <p>Una vez instalado, descarga el archivo <code>kubeconfig</code> en el directorio donde ejecutaste tu comando. Puedes configurar la variable de entorno <code>KUBECONFIG</code> con la ruta al archivo <code>kubeconfig</code> recientemente descargado.</p> <p>Ahora puedes usar <code>kubectl get nodes</code> para ver los nodos en tu cl\u00faster.</p>"},{"location":"instalacion/#nodo-worker","title":"Nodo worker","text":"<p>Finalmente, tenemos que configurar nuestro nodo trabajador donde desplegaremos nuestras aplicaciones y servicios.</p> <p>Para esto, toma la IP del <code>agent-worker</code> y pasa el mismo comando que antes, pero sin la bandera <code>--server</code>.</p> <pre><code>$ k3sup join --ip &lt;IP-del-agent-worker&gt; --user ubuntu --server-ip &lt;IP-del-master-node&gt; --server-user ubuntu\n</code></pre> <p>Ahora, si ejecutas <code>kubectl get nodes</code>, encontrar\u00e1s dos nodos maestros y un \u00fanico nodo trabajador que componen tu configuraci\u00f3n de cl\u00faster multinodo. Puedes crear nuevas VMs y agregar m\u00e1s nodos maestros o trabajadores dependiendo de c\u00f3mo planees utilizar tu cl\u00faster.</p>"},{"location":"instalacion/#referencias","title":"Referencias","text":"<p>oh my zsh!</p> <p>Linux KVM</p> <p>Minikube Documentaci\u00f3n Oficial</p> <p>Multipass Github Oficial</p> <p>k3sup Github Oficial</p> <p>Setting up multi-node Kubernetes cluster locally with K3s and Multipass</p> <p>Multi-node Kubernetes cluster setup using Multipass/k3s</p>"},{"location":"lens/","title":"Lens","text":"<p>Lens es un Entorno de Desarrollo Integrado (IDE) que permite a los usuarios conectar y gestionar m\u00faltiples cl\u00fasteres de Kubernetes desde plataformas Mac, Windows y Linux. Para equipos y organizaciones, Lens ha demostrado ser la forma m\u00e1s efectiva de aprender Kubernetes, aumentar la productividad del equipo y reducir las herramientas necesarias para el desarrollo nativo de la nube.</p> <p>La interfaz gr\u00e1fica rica en funciones e intuitiva permite a los usuarios implementar y gestionar sus cl\u00fasteres directamente desde la consola. Al mismo tiempo, los paneles de control integrados proporcionan m\u00e9tricas clave y conocimientos sobre todo lo que se ejecuta en el cl\u00faster, incluidas implementaciones, configuraciones, redes, almacenamiento, control de acceso e incluso recursos personalizados.</p> <p>Aqu\u00ed hay 3 diferenciadores clave que distinguen a Lens:</p> <ul> <li>Simplicidad: Como una aplicaci\u00f3n independiente, Lens brinda a los usuarios la capacidad de gestionar todos los cl\u00fasteres en cualquier plataforma simplemente cargando el archivo kubeconfig. Adem\u00e1s, como una interfaz gr\u00e1fica de usuario (GUI), Lens proporciona un enfoque de \"apuntar y hacer clic\" para la gesti\u00f3n de cl\u00fasteres que elimina la complejidad de trabajar en una interfaz de l\u00ednea de comandos (CLI).</li> <li>Accesibilidad: Lens permite a los usuarios crear un cat\u00e1logo unificado de cl\u00fasteres, servicios, cargas de trabajo, herramientas, automatizaciones y recursos relacionados para un f\u00e1cil acceso y una vista unificada de la supervisi\u00f3n en tiempo real. El acceso \u00fanico a eventos, registros y m\u00e9tricas permite a los usuarios solucionar errores y navegar f\u00e1cilmente para encontrar la causa ra\u00edz antes de que se convierta en un problema.</li> <li>Personalizaci\u00f3n completa: Las Extensiones de Lens agregan funcionalidad y servicios personalizados para acelerar los flujos de trabajo de desarrollo tanto para tecnolog\u00edas integradas con Kubernetes como para otras tecnolog\u00edas nativas de la nube. Los usuarios pueden elegir entre cientos de Extensiones de Lens construidas por la comunidad y el ecosistema nativo de la nube, o incluso crear las suyas propias.</li> </ul>"},{"location":"lens/#capturas","title":"Capturas","text":"<p>Kubernetes es una plataforma compleja con capacidades en constante expansi\u00f3n, lo que la convierte en una soluci\u00f3n poderosa para las empresas que se dirigen hacia la contenerizaci\u00f3n. Con su amplio conjunto de caracter\u00edsticas y su panel de control f\u00e1cil de usar, Lens proporciona un medio eficaz para simplificar la gesti\u00f3n multicloud tanto para desarrolladores nuevos como experimentados.</p> <p>Para las empresas que desean obtener los beneficios de Kubernetes sin lidiar con la complejidad, Lens es una opci\u00f3n que vale la pena considerar.</p>"},{"location":"proyecto/contributing/","title":"Contribuir","text":"<p>Nos emociona que est\u00e9s interesado en contribuir a nuestro proyecto. Esta gu\u00eda est\u00e1 dise\u00f1ada para ayudarte a entender c\u00f3mo puedes colaborar con  nosotros, ya sea corrigiendo errores, mejorando la documentaci\u00f3n,  agregando nuevas caracter\u00edsticas o cualquier otra forma de contribuci\u00f3n  que desees realizar.</p> <p>Para incorporar una funci\u00f3n en la rama <code>main</code>, simplemente se crea un \"PR\" (Pull Request), que deber\u00e1 ser aprobado por alg\u00fan colaborador. Cualquier colaborador puede hacerlo, o bien, si no requiere revisi\u00f3n, puede ser aceptado por quien est\u00e9 incluyendo la funcionalidad.</p> <p>Es crucial que el nombre de las ramas creadas sea lo m\u00e1s descriptivo posible. Por ejemplo, si trabajamos en una nueva funcionalidad relacionada con la API, la rama se debe llamar como referencia a la funcionalidad en cuesti\u00f3n. En el caso de tratarse de la correcci\u00f3n de un error en el c\u00f3digo de la API, la llamaremos <code>fix-api</code>.</p> <p>Este proceso asegura un flujo de trabajo ordenado y facilita la colaboraci\u00f3n entre los miembros del equipo.</p> <p>Los pasos para contribuir en este proyecto como individuo son:</p> <ol> <li>Forkear el repositorio (<code>git fork</code>)</li> <li>Crear una nueva rama para la funci\u00f3n (<code>git checkout -b feature/AmazingFeature</code>)</li> <li>Publicar la rama en el repositorio remoto(<code>git push --set-upstream origin &lt;nombre-de-la-nueva-rama&gt;</code>)</li> <li>Commit los cambios (<code>git commit -m 'Add some AmazingFeature'</code>)</li> <li>Push a la rama (<code>git push origin feature/AmazingFeature</code>)</li> <li>Abrir un Pull Request dirigido a la rama <code>develop</code></li> </ol>"},{"location":"proyecto/metodologia/","title":"Metodologia de Trabajo","text":"<p>En este apartado estaremos comentando algunas de las metodologias de trabajo que seran implementados durante el transcurso de la practica profesional. Este documento comenta todo tipo de tacticas que se implementan desde peque\u00f1os emprendimientos hasta en grandes empresas para mejorar la rapidez y la robustez del trabajo en cuestion.</p>"},{"location":"proyecto/metodologia/#manifiesto-agile","title":"Manifiesto Agile","text":"<p>El Manifiesto Agile es una declaracion de valores y pricipios sobre nuevas formas de desarrollar software como reaccion a los tradicionales metodos formales con los que se trabajaba entonces en la industria.</p> <p>El manifiesto propone descubrir nuevas formas de desarrollar software tanto por experiencia propia como ayudando a terceros bas\u00e1ndose en los siguientes valores:</p> <ul> <li>Individuos e interacciones sobre procesos y herramientas: las personas son lo m\u00e1s importante, por encima de los procesos y las herramientas, por su capacidad para ser creativas e innovar. Los procesos y las herramientas deben servir de apoyo para que las personas cumplan sus objetivos.</li> <li>Software funcionando sobre documentaci\u00f3n extensiva: las funcionalidades esperadas en software funcionando es m\u00e1s valioso que un documento muy detallado de requisitos, que adem\u00e1s ser\u00e1 muy dif\u00edcil de crear antes del desarrollo de un proyecto por la inestabilidad de su naturaleza. Es m\u00e1s interesante el feedback temprano que pueden dar los usuarios al interactuar con un prototipo o con el producto parcial.</li> <li>Colaboraci\u00f3n con el cliente sobre negociaci\u00f3n contractual: el cliente es un miembro m\u00e1s del equipo. La colaboraci\u00f3n continua con \u00e9l genera m\u00e1s valor que el cumplimiento estricto de un contrato, que no hace m\u00e1s que crear barreras y delimitar responsabilidades.</li> <li>Respuesta ante el cambio sobre seguir un plan: Es m\u00e1s valiosa la capacidad de respuesta y adaptaci\u00f3n a los cambios que la de seguir y asegurar el cumplimiento de los planes preestablecidos.</li> </ul> <p>Los 12 principios que se rigen en base a los valores mencionados anteriormente establecen que la mayor prioridad es satisfacer al cliente a pesar de los requisitos que nos proporcione. Entregar software de forma frecuente en donde los proyectos se desarrollen en torno a individuos motivados donde la comunicacion entre ambas partes sea constante y de forma cara a cara para una mayor efectividad. La medidad principal de progreso es el software funcionando donde la atencion continua y el buen dise\u00f1o mejora la agilidad. Los procesos agiles promueven el desarrollo sostenible capaz de mantener un ritmo constante y la simpleza debe reinar donde el equipo tiene que reflexionar de forma regular para poder perfeccionar el comportamiento en consecuencia.</p>"},{"location":"proyecto/metodologia/#scrum","title":"Scrum","text":"<p>Scrum es un marco de gesti\u00f3n de proyectos de metodolog\u00eda \u00e1gil que ayuda a los equipos a estructurar y gestionar el trabajo mediante un conjunto de valores, principios y pr\u00e1cticas. Al igual que un equipo de rugby (de donde proviene su nombre) cuando entrena para un gran partido, el m\u00e9todo scrum anima a los equipos a aprender a trav\u00e9s de las experiencias, a autoorganizarse mientras abordan un problema y a reflexionar sobre sus victorias y derrotas para mejorar continuamente.</p> <p>Scrum presenta tres funciones: el propietario del producto, el experto en scrum y los miembros del equipo de desarrollo. Las tres funciones de scrum describen las responsabilidades clave de los miembros del equipo de scrum. No son cargos, lo que significa que cualquier cargo, incluso los que tienes en la actualidad, puede desempe\u00f1ar una de las funciones. Como la esencia del scrum es el empirismo, la autoorganizaci\u00f3n y la mejora continua, las tres funciones dan una definici\u00f3n m\u00ednima de las responsabilidades y obligaciones para permitir a los equipos realizar el trabajo de manera eficaz; as\u00ed se consigue que asuman la tarea de organizarse y seguir mejorando.</p> <p>Scrum ofrece una estructura ligera con las tres funciones de scrum: miembro del equipo de desarrollo, propietario del producto y experto en scrum:</p> <ul> <li>Equipo de Desarrollo: El equipo de desarrollo es la gente que hace el trabajo. El equipo de desarrollo debe ser capaz de autoorganizarse para poder tomar decisiones con el fin de llevar a cabo el trabajo. </li> <li>Propietario del Producto: Los propietarios de producto que utilizan scrum conocen los requisitos de los clientes y la empresa y, a partir de ah\u00ed, crean y gestionan el backlog del producto en funci\u00f3n de ellos. Puesto que los equipos \u00e1giles son, por naturaleza, flexibles y receptivos, es responsabilidad del propietario del producto asegurarse de que ofrezcan el m\u00e1ximo valor. La empresa est\u00e1 representada por esta persona, que le dice al desarrollador lo que prima entregar. La confianza entre estos dos roles es crucial.</li> <li>Experto en Scrum: El experto en scrum es la funci\u00f3n que se encarga de unirlo todo y de garantizar que el scrum se haga bien. En t\u00e9rminos pr\u00e1cticos, eso significa que ayuda al propietario del producto a definir el valor, al equipo de desarrollo a entregarlo y al equipo de scrum a mejorar. Es un l\u00edder servidor que no solo representa un estilo de liderazgo de apoyo, sino que describe lo que hacen en el d\u00eda a d\u00eda.</li> </ul>"},{"location":"proyecto/metodologia/#objetivos-smart","title":"Objetivos SMART","text":"<p>Los objetivos SMART son espec\u00edficos, mensurables, alcanzables, relevantes y temporales. Son metas concretas que permiten analizar el desempe\u00f1o de nuestros esfuerzos, ya sea en marketing o en cualquier \u00e1rea de una empresa que requiera ordenar y medir su trabajo de manera sistem\u00e1tica.</p> <p></p> <p>Aplicar los objetivos SMART en proyectos y negocios ayuda a avanzar con m\u00e1s seguridad y con mayor control sobre el proceso. Definir los objetivos SMART te ayudar\u00e1 a enfocar tus esfuerzos en tus metas de una manera inteligente. Por esta raz\u00f3n, se trata de una herramienta que contribuye a una mayor productividad y eficiencia y reduce el estr\u00e9s laboral, al distribuir mejor los recursos y el tiempo.</p>"},{"location":"proyecto/metodologia/#flujos-de-trabajo","title":"Flujos de Trabajo","text":"<p>En este apartado se comentaran algunos de los flujos de Trabajo mas utilizados y elegiremos uno de ellos el cual sera utilizado en esta practica.</p>"},{"location":"proyecto/metodologia/#flujo-git","title":"Flujo Git","text":"<p>Es uno de los mas conocidos en donde se trabaja con 2 ramas principales que tienen duracion infinita:</p> <ul> <li>master: esta rama contiene el c\u00f3digo en produccion. Todo el c\u00f3digo desarrollado sera colocado en esta rama en cierto momento.</li> <li>develop: Esta rama contiene el c\u00f3digo en pre-produccion. Cuando las funcionalidades estan terminadas es cuando se colocan en produccion.</li> </ul> <p>Las ventajas es que asegura un estado de limpio de las ramas en todo momento del ciclo del proyecto, como as\u00ed tambien sigue un patron sistematico que hace mas facil el entendimiento. Las desventajas es que el historial se vuelve dificil de leer y no se recomienda cuando se necesita mantener una unica version en produccion.</p>"},{"location":"proyecto/metodologia/#flujo-github","title":"Flujo GitHub","text":"<p>Es considerada un flujo de trabajo liviano que cuenta con 6 principios principales:</p> <ul> <li>Cualquier cosa en la rama master es desplegable.</li> <li>Si se quiere trabajar con algo nuevo se crea una rama aparte y se le da un nombre descriptivo</li> <li>Se realizan commits de forma regular localmente como as\u00ed tambien a la misma rama que se encuentra en el servidor.</li> <li>Cuando se necesita ayuda o feedback, o directamente la rama esta lista para ser enviada al master, se hace un pull-request.</li> <li>Cuando alguien mas revise y apruebe la funcionalidad, se coloca en el master.</li> <li>Una vez en el master, se debe desplegar de inmediato.</li> </ul> <p>Es ideal para mantener una unica version en produccion y es amigable a las tecnicas de CD/CI. Pero el c\u00f3digo en produccion puede pasar a ser inestable facilmente.</p>"},{"location":"proyecto/metodologia/#flujo-gitlab","title":"Flujo GitLab","text":"<p>Combina el desarrollo centrado en las funcionalidades y las ramas de funcionalidades con rastreo de issues. La diferencia con GitHub es que no en todo momento se puede desplegar la aplicaci\u00f3n a producci\u00f3n. Se basa en 11 reglas, pero estas son las mas importantes:</p> <ul> <li>Usa ramas de funcionalidades, osea no hay commits en el master.</li> <li>Se prueban todos los commits.</li> <li>Se corren todas las pruebas en todos los commits.</li> <li>Se revisa el c\u00f3digo antes de colocarlo en el master.</li> <li>Los despliegues son autom\u00e1ticos</li> <li>Las etiquetas son puesta por el usuario.</li> </ul> <p>Define el comportamiento CD/CI, provoca que el historial de Git sea mas limpio pero es mas complejo.</p>"},{"location":"proyecto/metodologia/#flujo-unico","title":"Flujo \u00danico","text":"<p>La condici\u00f3n principal es que en cada lanzamiento de produccion sea basado en el lanzamiento anterior. Ademas no contiene rama de desarrollo.</p> <p>Las ventajas son que el historial es mas limpio y mas legible, flexible a decisi\u00f3n de equipo e ideal para la producci\u00f3n de una \u00fanica versi\u00f3n. Pero no se recomienda para CD/CI.</p>"},{"location":"proyecto/metodologia/#estructura-del-proyecto","title":"Estructura del Proyecto","text":"<p>La estructura de los proyecto es una de las primeras cosas a tener en cuenta debido a que hace al mismo proyecto reproducible.</p>"},{"location":"proyecto/metodologia/#consejos","title":"Consejos","text":"<ul> <li>Los archivos del proyecto van en una sola carpeta</li> <li>Utilizar estructuras consistentes e informativas</li> <li>Para separar los archivos privados de los p\u00fablicos se utiliza .gitignore o se lo coloca en una carpeta separada que no es git</li> <li>Se necesita un archivo README.md para describir el proyecto y las instrucciones para que el proyecto sea reproducible</li> <li>Organiza tus archivos en base a los componentes y no a los roles. Ademas, coloca los archivos de prueba al lado de los de implementaci\u00f3n.</li> </ul>"},{"location":"proyecto/metodologia/#estructura-basica","title":"Estructura B\u00e1sica","text":"<p>Aqu\u00ed se observa una estructura b\u00e1sica que puede representar un proyecto. Habitualmente la mayoria de los repositorios cuentan con esta estructura</p> <ul> <li>Carpeta src: Es la carpeta de c\u00f3digo fuente. Sin embargo, en lenguajes que usan encabezados (o si tienes un marco de trabajo para tu aplicaci\u00f3n) no coloques esos archivos aqu\u00ed.</li> <li>Carpeta test: Pruebas unitarias, pruebas de integraci\u00f3n.</li> <li>Carpeta .config: Debe contener la configuraci\u00f3n local relacionada con la configuraci\u00f3n en la m\u00e1quina local.</li> <li>Carpeta .build: Esta carpeta debe contener todos los scripts relacionados con el proceso de construcci\u00f3n (PowerShell, Docker compose\u2026).</li> <li>Carpeta dep: Este es el directorio donde se deben almacenar todas tus dependencias.</li> <li>Carpeta doc: La carpeta de documentaci\u00f3n</li> <li>Carpeta res: Para todos los recursos est\u00e1ticos en tu proyecto. Por ejemplo, im\u00e1genes.</li> <li>Carpeta samples: Proporciona ejemplos</li> <li>Carpeta tools: Directorio de conveniencia para tu uso. Debe contener scripts para automatizar tareas en el proyecto, por ejemplo, scripts de construcci\u00f3n, scripts de cambio de nombre. Generalmente contiene archivos .sh, .cmd por ejemplo.</li> </ul>"},{"location":"proyecto/metodologia/#estructura-actual","title":"Estructura Actual","text":"<p>Debido a nuestra metodolog\u00eda de trabajo, que consiste en dividir nuestro proyecto en distintas \u00e1reas de aplicaci\u00f3n, hemos decidido organizar nuestro c\u00f3digo fuente seg\u00fan la arquitectura que se utilice en cada momento. Por lo tanto, utilizaremos tres carpetas principales: <code>dev</code>,<code>lab</code> y <code>prd</code>. </p> <p>La carpeta <code>dev</code> contendr\u00e1 el c\u00f3digo fuente en desarrollo, donde se realizar\u00e1n cambios, pruebas y mejoras continuas. En <code>lab</code> se ubicar\u00e1 el c\u00f3digo fuente en fase de pruebas y validaciones, llevando a cabo pruebas exhaustivas antes de desplegar la aplicaci\u00f3n en un entorno de producci\u00f3n. Por \u00faltimo, en <code>prd</code> residir\u00e1 el c\u00f3digo fuente que est\u00e1 en producci\u00f3n, es decir, disponible para los usuarios finales, garantizando su estabilidad y funcionamiento \u00f3ptimo.</p> <p>Esta estructura organizativa nos permite mantener un flujo de trabajo eficiente y ordenado, facilitando la gesti\u00f3n y el mantenimiento del c\u00f3digo en cada etapa del ciclo de desarrollo del software. Adem\u00e1s, proporciona una clara separaci\u00f3n entre los diferentes entornos, lo que contribuye a la estabilidad y seguridad de nuestras implementaciones.</p> <pre><code>pps_fede_Ferro_2024/\n\u251c\u2500\u2500 docs/                 # Documentacion del Proyecto\n\u251c\u2500\u2500 src/                  # Contiene todo el c\u00f3digo del Proyecto\n     |\u2500\u2500 dev/             # Codigo perteneciente a Desarrollo\n     |\u2500\u2500 lab/             # Codigo perteneciente a Laboratorio\n     |\u2500\u2500 prd/             # Codigo perteneciente a Producci\u00f3n\n\u251c\u2500\u2500 README.md             # Previsualizaci\u00f3n del Proyecto\n</code></pre>"},{"location":"proyecto/metodologia/#commits","title":"Commits","text":"<p>La forma en que aplicaremos los commits est\u00e1n reglamentados en la especificaci\u00f3n Conventional Commits que nos provee una serie de reglas sencillas para poder crear un historial explicito de commits, donde sea mas f\u00e1cil escribir herramientas automatizadas encima de eso. La estructura esta basada en la siguiente forma: </p> <pre><code>&lt;tipo&gt;(enfoque opcional): &lt;descripcion&gt;\n</code></pre> <p>Los tipos mas utilizados y que se emplearan en este trabajo son:</p> <ul> <li>feat(tema de la modificaci\u00f3n): Breve explicaci\u00f3n: Para cambios significativos o nuevas caracter\u00edsticas.</li> <li>fix(tema de la modificaci\u00f3n): Breve explicaci\u00f3n: Para correcciones peque\u00f1as.</li> <li>chore(tema de la modificaci\u00f3n): Breve explicaci\u00f3n: Para cambios menores insignificantes para el usuario.</li> <li>docs: Breve explicaci\u00f3n: Para cambios que se realizan a la documentaci\u00f3n.</li> </ul> <p>El enfoque consiste en un sustantivo que describe la secci\u00f3n que representa el commit. Y por ultimo una peque\u00f1a descripci\u00f3n que resume los cambios realizados en el repositorio.</p> <p>Posteriormente se puede usar otras caracter\u00edsticas que nos ayudan a distinguir de una mejor manera los commits, pero lo mencionado anteriormente regula lo b\u00e1sico y representara lo que se va a utilizar en la actual practica.</p>"},{"location":"proyecto/metodologia/#readme","title":"README","text":"<p>Los archivos README contiene la informacion importante que el usuario tiene que leer antes de proceder. Suele ser la primera y unica observacion en el proyecto que tiene el usuario, entonces es importante explicar lo que hace el proyecto y como lo hace de manera efectiva. el README tiene que decir:</p> <ul> <li>Que es? (con contexto previo)</li> <li>Mostrar como funciona</li> <li>Mostrar como se usa</li> <li>Expresar otros detalles relevantes</li> </ul>"},{"location":"proyecto/metodologia/#elementos-claves","title":"Elementos claves","text":"<ul> <li>nombre: Buscar nombres que se expliquen por si mismos.</li> <li>breve descripcion: Una breve descripcion de una linea describiendo el proyecto ayuda a tener una idea de que hace el mismo.</li> <li>uso: Siempre es mejor mostrar el proyecto en una aplicacion real o ejemplo.</li> <li>elementos visuales: incluir screenshots o videos</li> <li>instalacion: proveerle y explicarle al usuario todo lo que necesita saber.</li> <li>licencia: aplicarla y mostrarla lo mas arriba posible.</li> <li>roadmap: explicar las ideas a futuro del proyecto.</li> </ul>"},{"location":"proyecto/metodologia/#recomendaciones","title":"Recomendaciones","text":"<ul> <li>Poner links de referencia donde sea posible para mayor entendimiento del proyecto.</li> <li>Poner el c\u00f3digo de ejemplo en el repositorio.</li> <li>Estado del Proyecto</li> </ul>"},{"location":"proyecto/metodologia/#puntos-de-estimacion","title":"Puntos de Estimaci\u00f3n","text":"<p>Mientras que la mayor\u00eda de los equipos estiman la dificultad de una tarea por tiempo (medio d\u00eda, una semana o un mes), los puntos de estimaci\u00f3n son un m\u00e9todo para medir el esfuerzo en una escala relativa. La asignaci\u00f3n de tareas en funci\u00f3n de la dificultad relativa permite una  descripci\u00f3n m\u00e1s precisa del esfuerzo que se espera para la tarea porque, a diferencia de las estimaciones de tiempo, los puntos de estimaci\u00f3n se refieren solo a la tarea en cuesti\u00f3n, no a los correos electr\u00f3nicos, las reuniones o los retrasos inesperados que podr\u00edan afectar el tiempo que  se tarda en completar la tarea.</p> <p>Los desarrolladores usan una sucesi\u00f3n de Fibonacci: 0, 0.5, 1, 2, 3, 5, 8, 13, 20, 40, 100, como una m\u00e9trica para medir los puntos de historia con el fin de obligar a los equipos a tomar decisiones claras. Por ejemplo, si tienes que completar un proyecto y alguien te pregunta  si te llevar\u00e1 3 o 4 horas, puedes dudar sobre c\u00f3mo responder porque la  diferencia es tan peque\u00f1a que es dif\u00edcil de adivinar. En cambio, si  alguien te preguntara si te llevar\u00e1 3 o 6 horas, probablemente tu  respuesta ser\u00eda mucho m\u00e1s clara.</p> <p></p>"},{"location":"proyecto/metodologia/#diagramas","title":"Diagramas","text":"<p>A la hora de hacer los diagramas, exploramos c\u00f3mo las representaciones visuales, como diagramas y gr\u00e1ficos, pueden ser creadas, versionadas y gestionadas utilizando pr\u00e1cticas y herramientas similares a las que se emplean en el desarrollo de software. Esta convergencia entre la visualizaci\u00f3n y el c\u00f3digo ofrece ventajas significativas en t\u00e9rminos de colaboraci\u00f3n, automatizaci\u00f3n y mantenimiento en entornos de desarrollo de software y operaciones de infraestructura. El principal beneficio de utilizar este concepto es que la mayor\u00eda de las herramientas de Diagramas como C\u00f3digo pueden ser guionizadas e integradas en un pipeline de construcci\u00f3n para generar documentaci\u00f3n autom\u00e1tica. </p> <p>En este caso hablaremos de la plataforma Diagrams que te permite dibujar la arquitectura de sistemas en la nube mediante c\u00f3digo Python, lo que te permite rastrear tu diagrama en cualquier SCM (sistema de control de versiones). Admite importantes proveedores como AWS, Azure, GCP, Kubernetes, OpenStack, Oracle Cloud, etc., pero tambi\u00e9n admite la representaci\u00f3n de infraestructura local.</p> <p>Para poder instalarlo necesitaremos instalar la librer\u00eda</p> <pre><code>pip install diagrams\n</code></pre> <p>Para posteriormente integrarlos en nuestros archivos de python, aqu\u00ed se observa un peque\u00f1o ejemplo</p> <pre><code>from diagrams import Diagram\nfrom diagrams.k8s.clusterconfig import HPA\nfrom diagrams.k8s.compute import Deployment, Pod, ReplicaSet\nfrom diagrams.k8s.network import Ingress, Service\n\nwith Diagram(\"Exposed Pod with 3 Replicas\", show=False):\n    net = Ingress(\"domain.com\") &gt;&gt; Service(\"svc\")\n    net &gt;&gt; [Pod(\"pod1\"),\n            Pod(\"pod2\"),\n            Pod(\"pod3\")] &lt;&lt; ReplicaSet(\"rs\") &lt;&lt; Deployment(\"dp\") &lt;&lt; HPA(\"hpa\")\n</code></pre> <p></p>"},{"location":"seguridad/autentificacion/","title":"Autentificaci\u00f3n","text":"<p>La autenticaci\u00f3n es un componente cr\u00edtico en la seguridad de sistemas inform\u00e1ticos, ya que garantiza que los usuarios que intentan acceder a un sistema son quienes dicen ser. En un mundo cada vez m\u00e1s conectado y digitalizado, la protecci\u00f3n de la identidad y los datos se vuelve fundamental. La autenticaci\u00f3n efectiva no solo implica verificar las credenciales de un usuario, como nombres de usuario y contrase\u00f1as, sino tambi\u00e9n emplear t\u00e9cnicas avanzadas para prevenir el acceso no autorizado.</p> <p>Este apartado explorar\u00e1 diversas estrategias de autenticaci\u00f3n desde una perspectiva de seguridad, en este caso se analiza la implementacion de un sistema que ya contiene toda la logica necesaria para soportar distintos metodos de autentifacacion y es capaz de integrar con multiples aplicaciones.</p>"},{"location":"seguridad/autentificacion/#authentik","title":"Authentik","text":"<p>Authentik es un proveedor de identidad de c\u00f3digo abierto, centrado en la flexibilidad y versatilidad. Con Authentik, los administradores de sitios web, desarrolladores de aplicaciones e ingenieros de seguridad tienen una soluci\u00f3n confiable y segura para la autenticaci\u00f3n en casi cualquier tipo de entorno. Hay acciones s\u00f3lidas de recuperaci\u00f3n disponibles para los usuarios y aplicaciones, incluida la gesti\u00f3n de perfiles de usuario y contrase\u00f1as. Puedes editar, desactivar o incluso suplantar un perfil de usuario r\u00e1pidamente, y establecer una nueva contrase\u00f1a para nuevos usuarios o restablecer una contrase\u00f1a existente.</p> <p>Puedes utilizar Authentik en un entorno existente para agregar soporte para nuevos protocolos, por lo que introducir Authentik en tu pila tecnol\u00f3gica actual no presenta desaf\u00edos de reestructuraci\u00f3n. Admitimos todos los proveedores principales, como OAuth2, SAML, LDAP y SCIM, para que puedas elegir el protocolo que necesitas para cada aplicaci\u00f3n.</p> <p>El producto Authentik proporciona las siguientes consolas:</p> <ul> <li>Interfaz de administraci\u00f3n: una herramienta visual para la creaci\u00f3n y gesti\u00f3n de usuarios y grupos, tokens y credenciales, integraciones de aplicaciones, eventos y los Flows que definen procesos de inicio de sesi\u00f3n y autenticaci\u00f3n est\u00e1ndar y personalizables. Los paneles visuales f\u00e1ciles de leer muestran el estado del sistema, los inicios de sesi\u00f3n recientes y eventos de autenticaci\u00f3n, y el uso de la aplicaci\u00f3n.</li> <li>Interfaz de usuario: esta vista de consola en Authentik muestra todas las aplicaciones e integraciones en las que has implementado Authentik. Haz clic en la aplicaci\u00f3n a la que deseas acceder para abrirla, o profundiza para editar su configuraci\u00f3n en la interfaz de administraci\u00f3n.</li> <li>Flows: Los Flows son los pasos por los cuales ocurren las diversas Etapas de un proceso de inicio de sesi\u00f3n y autenticaci\u00f3n. Una etapa representa un solo paso de verificaci\u00f3n o l\u00f3gica en el proceso de inicio de sesi\u00f3n. Authentik permite la personalizaci\u00f3n y definici\u00f3n exacta de estos flujos.</li> </ul>"},{"location":"seguridad/autentificacion/#integracion-con-grafana","title":"Integraci\u00f3n con Grafana","text":"<p>Para probar la aplicacion y evaluar futuras implementaciones, se ha puesto a prueba con una simple integracion con grafana. La instalacion consta de los siguientes comandos, los archivos utilizados estaran en <code>src/dev/</code></p> <pre><code>minikube start --driver=kvm2 --memory=3g  \n\n# Authentik Instalation\n\nhelm repo add authentik https://charts.goauthentik.io\nhelm repo update\nhelm upgrade --install authentik authentik/authentik -f authentik-values.yaml\n\n# Authentik Service\n\nexport POD_AUTHENTIK=$(kubectl get pods -l \"app.kubernetes.io/component=server\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl label pod $POD_AUTHENTIK app=authentik\nkubectl apply -f authentik-service.yaml\nminikube service authentik-service\n</code></pre> <p>Para ingresar al servicio, tendremos que entrar con el link correspondiente al puerto 443 ya que utilizaremos el protocolo https. Nuestras credenciales de ingreso es Usuario: akadmin, contrase\u00f1a: prueba123</p> <p>Una vez a dentro de la interfaz crearemos un nuevo proveedor para nuestra aplicacion, en donde seleccionaremos OAuth2/OpenID Provider y el resto se coloca por default. Como Redirect URI colocamos <code>http://localhost:3000/login/generic_oauth</code></p> <p>Con eso vamos a crear la aplicacion y le colocaremos un slug a eleccion. Para mas informacion, dirigirse a la documentaci\u00f3n oficial de Authentik</p> <p>Con todos estos datos que nos da la plataforma, los anotamos en <code>grafana-values.yaml</code> en el apartado grafana.ini</p> <pre><code>grafana.ini:\n    paths:\n      data: /var/lib/grafana/\n      logs: /var/log/grafana\n      plugins: /var/lib/grafana/plugins\n      provisioning: /etc/grafana/provisioning\n    analytics:\n      check_for_updates: true\n    log:\n      mode: console\n    grafana_net:\n      url: https://grafana.net\n    server:\n      domain: localhost\n    auth:\n        signout_redirect_url: \"\"\n        oauth_auto_login: true\n    auth.generic_oauth:\n        name: authentik\n        enabled: true\n        client_id: \"\"\n        client_secret: \"\"\n        scopes: \"openid profile email\"\n        auth_url: \"\"\n        token_url: \"\"\n        api_url: \"\"\n        # Optionally map user groups to Grafana roles\n        role_attribute_path: contains(groups[*], 'authentik Admins') &amp;&amp; 'Admin' || contains(groups[*], 'Grafana Editors') &amp;&amp; 'Editor' || 'Viewer'\n        tls_skip_verify_insecure: true\n    cookie_samesite: none\n    cookie_secure: false\n</code></pre> <p>Los valores en blanco seran rellenados con los datos provistos. Una vez finalizado se guarda y procede a instalar Grafana</p> <pre><code># Grafana Instalation\n\nhelm repo add grafana https://grafana.github.io/helm-charts\nhelm repo update\nkubectl create namespace monitoring\nhelm install my-grafana grafana/grafana --namespace monitoring\n\n# Una vez instalado y funcionando, se le aplica las modificaciones realizadas anteriormente\n\nhelm upgrade my-grafana grafana/grafana -f grafana-values.yaml -n monitoring\n\n# Exponemos el Servicio\n\nexport POD_NAME=$(kubectl get pods --namespace monitoring -l \"app.kubernetes.io/name=grafana,app.kubernetes.io/instance=my-grafana\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl --namespace monitoring port-forward $POD_NAME 3000\n</code></pre> <p>ingresamos con el localhost:3000 y se vera en funcionamiento</p>"},{"location":"seguridad/autentificacion/#integracion-con-la-plataforma-de-monitoreo","title":"Integraci\u00f3n con la plataforma de Monitoreo","text":"<p>Para lograr el mismo resultado llegado en la seccion anterior pero con la utilizacion de nuestra ya implementada plataforma de monitoreo. Utilizaremos el script <code>authentication.sh</code> que se encuentra en <code>src/dev</code> que se encargara de la instalacion de Authentik.</p> <p>Una vez creado toda la configuracion de nuestro proveedor y aplicacion, instalamos nuestro stack de monitoreo ejecutando <code>monitoring.sh</code>.</p> <p>En este caso la configuracion tiene que ser colocado en el configmap <code>ConfigMap-grafana.yaml</code> que tendra este formato:</p> <pre><code>  data:\n    grafana.ini: |\n      [analytics]\n      check_for_updates = true\n      [grafana_net]\n      url = https://grafana.net\n      [log]\n      mode = console\n      [paths]\n      data = /var/lib/grafana/\n      logs = /var/log/grafana\n      plugins = /var/lib/grafana/plugins\n      provisioning = /etc/grafana/provisioning\n      [server]\n      domain = localhost\n      [auth]\n      signout_redirect_url = https://authentik.company/application/o/&lt;Slug of the application from above&gt;/end-session/\n      oauth_auto_login = true\n      [auth.generic_oauth]\n      name = authentik\n      enabled = true\n      client_id = &lt;Client ID from above&gt;\n      client_secret = &lt;Client Secret from above&gt;\n      scopes = openid email profile\n      auth_url = https://authentik.company/application/o/authorize/\n      token_url = https://authentik.company/application/o/token/\n      api_url = https://authentik.company/application/o/userinfo/\n      role_attribute_path = contains(groups, 'authentik Admins') &amp;&amp; 'Admin' || contains(groups, 'Grafana Editors') &amp;&amp; 'Editor' || 'Viewer'\n      tls_skip_verify_insecure = true\n      [security]\n      cookie_samesite = none\n      cookie_secure = false\n</code></pre> <p>Esta informacion tiene que ser colocada en el configmap que se encuentra en el cluster por lo tanto lo editaremos el configmap y pondremos lo escrito anteriormente:</p> <pre><code>kubectl edit cm loki-grafana -n loki\n</code></pre> <p>Tenemos que borrar el pod para que la configuracion se ejecute</p> <pre><code>kubectl delete pod &lt;nombre del pod&gt; -n loki\n</code></pre> <p>Veremos el resultado final ingresando a http::/localhost:3000</p>"},{"location":"seguridad/monitoreo/","title":"Monitoreo","text":""},{"location":"seguridad/monitoreo/#plg-stack","title":"PLG Stack","text":"<p>No te sorprendas si no encuentras este acr\u00f3nimo, es m\u00e1s conocido como Grafana Loki. De todos modos, este conjunto de herramientas est\u00e1 ganando popularidad debido a sus decisiones de dise\u00f1o concretas. Quiz\u00e1s conozcas Grafana, que es una herramienta de visualizaci\u00f3n popular. Grafana Labs dise\u00f1\u00f3 Loki, que es un sistema de agregaci\u00f3n de registros horizontalmente escalable, altamente disponible y multiinquilino inspirado en Prometheus. Solo indexa metadatos y no el contenido del registro. Esta decisi\u00f3n de dise\u00f1o lo hace muy rentable y f\u00e1cil de operar.</p> <p>Promtail es un agente que manda los logs del sistema local al cluster de Loki.</p> <p>Grafana es la herramienta de visualizaci\u00f3n que consume la informaci\u00f3n proveniente de Loki.</p> <p>Loki se construye sobre los mismos principios de dise\u00f1o que Prometheus, por lo tanto, es una buena opci\u00f3n para almacenar y analizar los registros de Kubernetes.</p> <p></p>"},{"location":"seguridad/monitoreo/#componentes","title":"Componentes","text":"<ul> <li>Promtail: Este es el agente que se instala en los nodos (como Daemonset); extrae los registros de los trabajos y se comunica con el servidor de API de Kubernetes para obtener los metadatos y utilizar esta informaci\u00f3n para etiquetar los registros. Luego, reenv\u00eda el registro al servicio central de Loki. Los agentes admiten las mismas reglas de etiquetado que Prometheus para asegurarse de que los metadatos coincidan.</li> <li>Distribuidor: Promtail env\u00eda registros al distribuidor, que act\u00faa como un b\u00fafer. Para manejar millones de escrituras, agrupa el flujo de entrada y lo comprime en bloques a medida que llegan. Hay m\u00faltiples ingesters, los registros pertenecientes a cada flujo terminar\u00edan en el mismo ingester para todas las entradas relevantes en el mismo bloque. Esto se hace utilizando el anillo de ingesters y el hashing consistente. Para proporcionar resiliencia y redundancia, lo hace n veces (predeterminado 3).</li> <li>Ingester: A medida que llegan los bloques, se comprimen con gzip y se agregan registros. Una vez que el bloque se llena, se vuelca en la base de datos. Los metadatos van a Index y los datos de registro del bloque van a Chunks (generalmente en un almacenamiento de objetos). Despu\u00e9s del volcado, el ingester crea un nuevo bloque y agrega nuevas entradas en \u00e9l.</li> </ul> <p>Algunos de los terminos basicos utilizados son:</p> <ul> <li>Index: El \u00edndice es una base de datos como DynamoDB, Cassandra, Google Bigtable, etc.</li> <li>Chunks: El bloque de registros en formato comprimido se almacena en los almacenes de objetos como S3.</li> <li>Querier: Esto est\u00e1 en la ruta de lectura y realiza todo el trabajo pesado. Dado el rango de tiempo y el selector de etiquetas, busca en el \u00edndice para averiguar cu\u00e1les son los bloques coincidentes. Luego, lee esos bloques y realiza una b\u00fasqueda para obtener el resultado.</li> </ul> <p>Una vez que el chunk \"se llena\", lo volcamos en la base de datos.</p> <p></p>"},{"location":"seguridad/monitoreo/#arquitectura","title":"Arquitectura","text":""},{"location":"seguridad/monitoreo/#fluentbit","title":"FluentBit","text":"<p>Fluent Bit es una navaja suiza de c\u00f3digo abierto y multiplataforma para procesamiento y distribuci\u00f3n de registros. En la actualidad, los datos provienen de diversas fuentes y Fluent Bit est\u00e1 aqu\u00ed para ayudarte a agregar y procesar todos tus datos de manera confiable, segura y flexible.</p> <p>Fluent Bit se basa en algunos conceptos fundamentales que son muy importantes para entender c\u00f3mo funciona.</p>"},{"location":"seguridad/monitoreo/#conceptos-claves","title":"Conceptos Claves","text":"<ul> <li>Evento o Registro: t\u00e9rminos intercambiables que se refieren a cada pieza de datos que es recuperada por Fluent Bit.</li> <li>Etiqueta: Una Etiqueta se especifica manualmente (en la mayor\u00eda de los casos) en la configuraci\u00f3n del Plugin de Entrada y es utilizada por el Enrutador para identificar informaci\u00f3n y determinar a trav\u00e9s de qu\u00e9 Filtro o Salida debe pasar la informaci\u00f3n.</li> <li>Coincidencia: Cuando hablamos de Etiquetas, dijimos que una Etiqueta es utilizada por el Enrutador para identificar informaci\u00f3n y decidir d\u00f3nde enviarla. Una Coincidencia es c\u00f3mo el enrutador sabe qui\u00e9n debe recibir la informaci\u00f3n. Los Enrutadores entregan la informaci\u00f3n a quien tenga una Coincidencia que coincida con la propiedad de configuraci\u00f3n especificada Etiqueta en el plugin de entrada. Coincidencia es una propiedad de configuraci\u00f3n presente en la configuraci\u00f3n de Filtros y Plugins de Salida.</li> <li>Mensajes Estructurados: Ya sean estructurados o no, cada Evento que es manejado por Fluent Bit se convierte en un mensaje estructurado, mediante el formato de datos MessagePack. Los mensajes estructurados ayudan a Fluent Bit a implementar operaciones m\u00e1s r\u00e1pidas.</li> </ul>"},{"location":"seguridad/monitoreo/#pipeline","title":"Pipeline","text":"<p>Ahora que conocemos los conceptos clave de Fluent Bit y el mecanismo de almacenamiento en b\u00fafer, debes estar pregunt\u00e1ndote \"pero \u00bfc\u00f3mo funciona todo internamente?\"</p> <p>Trabajando como un agregador y reenviador de registros, Fluent Bit tiene su propia forma de recuperar, organizar, modificar y reenviar toda la informaci\u00f3n que maneja.</p> <p>Este proceso se llama Tuber\u00eda de Datos, que es un camino por el cual toda la informaci\u00f3n recuperada por los Plugins de Entrada de Fluent Bit debe pasar.</p> <p>Nos referiremos a cada parte de esta tuber\u00eda como etapas.</p> <p></p>"},{"location":"seguridad/monitoreo/#instalacion","title":"Instalaci\u00f3n","text":"<p>Aqu\u00ed tienes una versi\u00f3n mejorada:</p> <p>Para instalar la estructura de monitoreo de logs, simplemente descarga el script <code>loki-setup.sh</code> ubicado en la carpeta <code>/src/dev</code> de nuestro repositorio en GitHub. Aseg\u00farate de otorgarle los permisos de ejecuci\u00f3n adecuados antes de proceder con la instalaci\u00f3n.</p> <pre><code>sudo chmod +x loki-setup.sh\n./loki-setup.sh\n</code></pre> <p>Una vez completada la instalaci\u00f3n, puedes acceder a Grafana de forma local mediante el siguiente comando:</p> <pre><code>kubectl port-forward --namespace loki service/loki-grafana 3000:80\n</code></pre> <p>Despu\u00e9s de ejecutar este comando, podr\u00e1s ingresar a Grafana a trav\u00e9s de tu navegador web favorito, utilizando la direcci\u00f3n http://localhost:3000. Utiliza las credenciales de inicio de sesi\u00f3n proporcionadas anteriormente, con el usuario admin y la contrase\u00f1a que obtuviste durante el proceso de instalaci\u00f3n.</p>"},{"location":"seguridad/monitoreo/#referencias","title":"Referencias","text":"<p>https://www.infracloud.io/blogs/logging-in-kubernetes-efk-vs-plg-stack/</p> <p>https://codersociety.com/blog/articles/loki-kubernetes-logging</p> <p>https://faun.pub/fluent-bit-a-brief-introduction-3a9044312fe3</p> <p>https://artifacthub.io/packages/helm/grafana/loki-stack</p>"},{"location":"seguridad/scanning/","title":"Escaneo","text":"<p>El escaneo de seguridad en Kubernetes es un proceso fundamental para garantizar la integridad y protecci\u00f3n de los entornos de contenedores y las aplicaciones desplegadas. Kubernetes, al ser una plataforma de orquestaci\u00f3n de contenedores, gestiona el despliegue, escalado y operaci\u00f3n de aplicaciones contenedorizadas, lo que lo convierte en un objetivo atractivo para posibles ataques. Por ello, implementar pr\u00e1cticas de seguridad robustas es esencial.</p> <p>El escaneo de seguridad en Kubernetes se centra en dos \u00e1reas principales: la b\u00fasqueda de vulnerabilidades y el escaneo de manifiestos. La b\u00fasqueda de vulnerabilidades implica la identificaci\u00f3n de fallos de seguridad en las im\u00e1genes de contenedores, configuraciones y dependencias utilizadas por las aplicaciones. Este proceso puede detectar problemas como software desactualizado, configuraciones inseguras y dependencias vulnerables, permitiendo a los administradores remediar estos problemas antes de que sean explotados.</p> <p>Por otro lado, el escaneo de manifiestos se refiere a la revisi\u00f3n y an\u00e1lisis de los archivos de configuraci\u00f3n de Kubernetes, com\u00fanmente escritos en YAML o JSON, que definen el estado deseado del cl\u00faster y sus componentes. Estos manifiestos incluyen configuraciones para pods, servicios, despliegues, entre otros. El objetivo del escaneo de manifiestos es asegurar que las configuraciones siguen las mejores pr\u00e1cticas de seguridad y cumplimiento normativo, previniendo configuraciones inseguras como permisos excesivos, falta de pol\u00edticas de red, y uso incorrecto de secretos.</p> <p>En conjunto, estas pr\u00e1cticas de escaneo permiten mantener un entorno de Kubernetes m\u00e1s seguro y resiliente, reduciendo la superficie de ataque y mitigando los riesgos asociados con las operaciones de contenedores. Implementar herramientas y procesos automatizados para el escaneo de vulnerabilidades y de manifiestos es crucial para cualquier organizaci\u00f3n que dependa de Kubernetes para sus aplicaciones y servicios.</p>"},{"location":"seguridad/scanning/#kubescape","title":"Kubescape","text":"<p>Kubescape es una plataforma de seguridad de Kubernetes de c\u00f3digo abierto que incluye an\u00e1lisis de riesgos, cumplimiento de seguridad y escaneo de configuraciones incorrectas. Est\u00e1 dirigido a practicantes de DevSecOps o ingenieros de plataformas, ofreciendo una interfaz CLI f\u00e1cil de usar, formatos de salida flexibles y capacidades de escaneo automatizadas. Ayuda a los usuarios y administradores de Kubernetes a ahorrar tiempo, esfuerzo y recursos valiosos.</p> <p>Kubescape puede escanear cl\u00fasteres, archivos YAML y Helm charts, detectando configuraciones incorrectas seg\u00fan m\u00faltiples marcos (incluidos NSA-CISA, MITRE ATT&amp;CK\u00ae y el CIS Benchmark). Se puede utilizar tanto como CLI como operador dentro del cl\u00faster mismo.</p>"},{"location":"seguridad/scanning/#cli","title":"CLI","text":"<p>El CLI de Kubescape consta de un solo binario que se puede descargar y poner en marcha con los siguientes comandos:</p> <pre><code>curl -s https://raw.githubusercontent.com/kubescape/kubescape/master/install.sh | /bin/bash\nexport PATH=$PATH:/home/&lt;user&gt;/.kubescape/bin \n</code></pre> <p>Ejecutar <code>kubescape scan</code> sin otros par\u00e1metros realizar\u00e1 el escaneo de seguridad de visi\u00f3n general/baseline del cl\u00faster. Esto realiza algunas comprobaciones clave de seguridad y muestra el n\u00famero de recursos que tienen ciertos permisos. Luego, puedes configurar reglas de aceptaci\u00f3n de riesgos para permitir elementos que se han instalado o configurado deliberadamente en tu cl\u00faster.</p> <p>Por ejemplo, el malware en un cl\u00faster a menudo intentar\u00e1 crear un rol de administrador del cl\u00faster o un rol con permisos similares. Con el escaneo baseline de Kubescape, puedes identificar qu\u00e9 roles has instalado que deben tener estos permisos, y luego ver f\u00e1cilmente o ser notificado cuando la configuraci\u00f3n cambie desde tu baseline segura.</p> <p>Para ejecutar un escaneo con un marco espec\u00edfico, utiliza el siguiente comando:</p> <pre><code>kubescape scan framework &lt;framework&gt;\n</code></pre> <p>En modo verbose (cuando se proporciona la bandera <code>--verbose</code>), Kubescape realizar\u00e1 un escaneo de tu cl\u00faster especificado como de costumbre. La salida incluir\u00e1 entonces informaci\u00f3n por recurso para cada recurso que desencaden\u00f3 un fallo de control, incluyendo un enlace a la documentaci\u00f3n para ese control y asistencia en la remediaci\u00f3n. Kubescape sugerir\u00e1 qu\u00e9 par\u00e1metros pueden ser cambiados para mitigar o eliminar el fallo.</p> <p>Kubescape tambi\u00e9n se puede utilizar para escanear manifiestos antes de ponerlos en producci\u00f3n:</p> <pre><code>kubescape scan *.yaml                  # Escanea todos los manifiestos en el directorio\nkubescape scan &lt;url de github&gt;         # Escanea todos los manifiestos en un repositorio de GitHub\nkubescape scan &lt;/path/to/directory&gt;    # Escanea todos los manifiestos dentro de un Helm Chart\n</code></pre>"},{"location":"seguridad/scanning/#operador","title":"Operador","text":"<p>La instalaci\u00f3n consta de utilizar el siguiente comando</p> <pre><code>helm repo add kubescape https://kubescape.github.io/helm-charts/\nhelm repo update\nhelm upgrade --install kubescape kubescape/kubescape-operator -n kubescape --create-namespace --set clusterName=`kubectl config current-context` --set capabilities.continuousScan=enable\n</code></pre> <p>Cuando se instala en tu cl\u00faster, Kubescape se ejecuta como un conjunto de microservicios. Estos te permiten monitorear continuamente la postura de seguridad del cl\u00faster en el que est\u00e1 instalado el operador.</p> <p>El operador Kubescape incluye:</p> <ul> <li>Escaneo de configuraciones incorrectas.</li> <li>Escaneo de todas las im\u00e1genes implementadas en busca de vulnerabilidades (CVE).</li> <li>Exposici\u00f3n de datos dentro del cl\u00faster como objetos de la API de Kubernetes.</li> <li>Exportaci\u00f3n de datos a un proveedor configurado.</li> <li>Permitir un control seguro por parte de un proveedor configurado.</li> </ul> <p>El microservicio <code>storage</code> proporciona un servidor de API agregado para exponer los datos de escaneo de Kubescape dentro del cl\u00faster.</p> <p>Los resultados del escaneo dentro del cl\u00faster se consideran ef\u00edmeros, ya que se actualizan regularmente y pueden regenerarse por completo. Si deseas un historial, se recomienda que utilices la interfaz del proveedor de Kubescape para enviar los datos fuera del cl\u00faster cuando los escaneos est\u00e9n completos.</p> <p>Para ver una lista de los tipos que se agregan a tu cl\u00faster, utiliza <code>kubectl api-resources</code>.</p> <p>El operador Kubescape incluye un componente que realiza escaneos de vulnerabilidades de todas las im\u00e1genes de contenedor que se est\u00e1n ejecutando en tu cl\u00faster.</p> <p>El componente <code>Kubevuln</code> escanea im\u00e1genes que se implementan en el cl\u00faster cuando:</p> <ul> <li>Se crea un nuevo Deployment, StatefulSet, DaemonSet o Pod desnudo.</li> <li>Se cambia la etiqueta de la imagen del contenedor en un Deployment, StatefulSet, DaemonSet o Pod existente.</li> </ul> <p>Utiliza el motor Grype para evaluar contra una base de datos de vulnerabilidades conocidas de una variedad de fuentes de datos de vulnerabilidades p\u00fablicamente disponibles. Las fuentes incluyen los datos de anuncios de seguridad de todas las distribuciones de Linux principales, la Base de Datos Nacional de Vulnerabilidades y los avisos de seguridad de GitHub.</p> <p>Los resultados est\u00e1n disponibles en objetos de API expuestos por el motor de almacenamiento de Kubescape.</p>"},{"location":"seguridad/scanning/#resultados","title":"Resultados","text":"<p>Kubescape proporciona resultados de escaneo como Recursos Personalizados para que puedas acceder a ellos de la misma manera conveniente que accedes a otros objetos de Kubernetes. Por ejemplo, para obtener una vista panor\u00e1mica de la seguridad de tu cl\u00faster, puedes ver el resumen del escaneo de configuraci\u00f3n a nivel de cl\u00faster con el siguiente comando:</p> <pre><code>kubectl get workloadconfigurationscansummaries -o yaml\n</code></pre> <p>Ejecutar este comando devolver\u00e1 una lista en formato YAML de los res\u00famenes de escaneo de configuraci\u00f3n para tu cl\u00faster por namespaces.</p> <p>En cl\u00fasteres con muchos namespaces, los resultados pueden ser abrumadores e incluso pueden exceder el historial de tu terminal. Dado que Kubescape sirve los resultados como objetos de Kubernetes, que son archivos YAML al final del d\u00eda, puedes aplicar tus procesos habituales para agregarlos de manera legible. Por ejemplo, redir\u00edgelos a archivos, editores de texto, etc. Com\u00fanmente usamos el siguiente comando:</p> <pre><code>kubectl get workloadconfigurationscansummaries -o yaml | less\n</code></pre> <p>De esta manera, obtienes el resultado completo en un archivo y puedes navegar por \u00e9l como mejor te convenga.</p>"},{"location":"seguridad/scanning/#referencias","title":"Referencias","text":"<p>Documentaci\u00f3n de Kubescape</p>"},{"location":"seguridad/seguridad/","title":"Seguridad","text":""},{"location":"seguridad/seguridad/#1-configuraciones-de-aplicaciones-inseguras","title":"1. Configuraciones de aplicaciones inseguras","text":"<p>El contexto de seguridad en una aplicacion es altamente configurable que puede generar configuraciones no seguras a lo largo de otras aplicaciones o el cluster mismo.</p> <p>Los manifiestos de Kubernetes contienen muchas configuraciones diferentes que pueden afectar la confiabilidad, seguridad y escalabilidad de una aplicaci\u00f3n dada. Estas configuraciones deben ser auditadas y corregidas continuamente. A continuaci\u00f3n, se presentan algunos ejemplos de configuraciones de manifiestos de alto impacto:</p> <ul> <li>Los procesos no deben ejecutarse como root: Ejecutar el proceso dentro de un contenedor como el usuario root es una mala configuraci\u00f3n com\u00fan en muchos cl\u00fasteres. Aunque root puede ser un requisito absoluto para algunas cargas de trabajo, debe evitarse siempre que sea posible. Si el contenedor fuera comprometido, el atacante tendr\u00eda privilegios de nivel root que permitir\u00edan acciones como iniciar un proceso malicioso que de otro modo no estar\u00eda permitido con otros usuarios en el sistema.</li> <li>Los archivos del sistema con lectura unicamente: Para limitar el impacto de un contenedor comprometido en un nodo de Kubernetes, se recomienda utilizar sistemas de archivos de solo lectura siempre que sea posible. Esto evita que un proceso o aplicaci\u00f3n maliciosa escriba en el sistema anfitri\u00f3n. Los sistemas de archivos de solo lectura son un componente clave para prevenir la evasi\u00f3n de contenedores.</li> <li>Containers con privilegios deben ser desactivados: Al configurar un contenedor como privilegiado dentro de Kubernetes, el contenedor puede acceder a recursos adicionales y capacidades del kernel del host. Las aplicaciones que se ejecutan como root, combinados con contenedores privilegiados, pueden ser devastadores, ya que el usuario puede obtener acceso completo al host. Sin embargo, esto se limita cuando se ejecuta como un usuario que no es root. Los contenedores privilegiados son peligrosos ya que eliminan muchos de los mecanismos de aislamiento integrados en los contenedores.</li> <li>Los recursos deben ser expresados: En Kubernetes, de manera predeterminada, los contenedores se ejecutan con recursos de c\u00f3mputo no limitados en un cl\u00faster. Sin embargo, se pueden asignar solicitudes y l\u00edmites de CPU a contenedores individuales dentro de un pod para gestionar mejor el uso de recursos y garantizar un rendimiento predecible. Aunque es una pr\u00e1ctica com\u00fan establecer l\u00edmites de CPU en Kubernetes, no siempre es necesario y, en muchos casos, puede ser contraproducente. La creencia de que siempre se necesitan l\u00edmites de CPU puede llevar a una  configuraci\u00f3n ineficiente y problemas de rendimiento, siendo el  principal problema el throttling de CPU. Por lo que lo ideal seria asignarle los recursos necesarios y no limitar el CPU.</li> </ul> <p>Una de las herramientas que utilizamos para que corroborar que los manifiestos cumplan con estas pautas de seguridad y otras mas es Kubescape, que se utiliza para escanear configuraciones y pol\u00edticas en los entornos de Kubernetes para detectar posibles vulnerabilidades y malas configuraciones que podr\u00edan poner en riesgo la seguridad de la infraestructura.</p>"},{"location":"seguridad/seguridad/#2-modo-rootless","title":"2. Modo Rootless","text":"<p>Los contenedores rootless se refieren a la capacidad de un usuario sin privilegios para crear, ejecutar y gestionar contenedores. Este t\u00e9rmino tambi\u00e9n incluye la variedad de herramientas relacionadas con los contenedores que tambi\u00e9n pueden ser ejecutadas por un usuario sin privilegios.</p> <p>\"Usuario sin privilegios\" en este contexto se refiere a un usuario que no tiene derechos administrativos y \"no est\u00e1 en los buenos t\u00e9rminos del administrador\" (en otras palabras, no tienen la capacidad de solicitar m\u00e1s privilegios o que se instalen paquetes de software).</p> <p>Pros:</p> <ul> <li>Puede mitigar potenciales vulnerabilidades de escape de contenedores (no es una panacea, por supuesto).</li> <li>Amigable con m\u00e1quinas compartidas, especialmente en entornos de HPC (computaci\u00f3n de alto rendimiento).</li> </ul> <p>Contras:</p> <ul> <li>Complejidad</li> </ul> <p>Cuando hablamos de contenedores rootless, nos referimos a ejecutar todo el runtime del contenedor, as\u00ed como los contenedores, sin privilegios de root.</p> <p>Incluso cuando los contenedores est\u00e1n ejecut\u00e1ndose como usuarios sin privilegios, si el runtime todav\u00eda se est\u00e1 ejecutando como root, no los llamamos contenedores rootless.</p> <p>Aunque permitimos el uso de binarios setuid (y/o setcap) para algunas configuraciones esenciales, como newuidmap, cuando una gran parte del runtime se ejecuta con setuid, no lo llamamos contenedores rootless. Tampoco los llamamos contenedores rootless cuando el usuario root dentro de un contenedor est\u00e1 mapeado al usuario root fuera del contenedor.</p>"},{"location":"seguridad/seguridad/#rootless-en-k3s","title":"Rootless en K3s","text":"<p>El modo rootless permite ejecutar servidores K3s como un usuario sin privilegios, con el fin de proteger al root real en el host de posibles ataques de escape de contenedores. Esta implementacion cuenta con algunas limitaciones conocidas</p>"},{"location":"seguridad/seguridad/#limitaciones","title":"Limitaciones","text":"<ul> <li>Puertos</li> </ul> <p>Cuando se ejecuta en modo rootless, se crea un nuevo espacio de nombres de red. Esto significa que la instancia de K3s se ejecuta con una red bastante separada del host. La \u00fanica forma de acceder a los Servicios que se ejecutan en K3s desde el host es configurar reenv\u00edos de puertos al espacio de nombres de red de K3s. K3s rootless incluye un controlador que enlazar\u00e1 autom\u00e1ticamente el puerto 6443 y los puertos de servicios por debajo de 1024 al host con un desplazamiento de 10000.</p> <p>Por ejemplo, un Servicio en el puerto 80 se convertir\u00e1 en 10080 en el host, pero 8080 se mantendr\u00e1 en 8080 sin ning\u00fan desplazamiento. Actualmente, solo los Servicios LoadBalancer se enlazan autom\u00e1ticamente.</p> <ul> <li>Cgroup</li> </ul> <p>Cgroup v1 y el modo h\u00edbrido v1/v2 no son compatibles; solo se admite Cgroup v2 puro. Si K3s no logra iniciarse debido a la falta de cgroups cuando se ejecuta en modo rootless, es probable que tu nodo est\u00e9 en modo h\u00edbrido, y los cgroups \"faltantes\" a\u00fan est\u00e9n enlazados a un controlador v1.</p> <ul> <li>Cluster Multinodo</li> </ul> <p>Actualmente, los cl\u00fasteres rootless multinodo o m\u00faltiples procesos rootless de K3s en el mismo nodo no son compatibles.</p>"},{"location":"seguridad/seguridad/#implementacion-con-multipass-y-k3sup","title":"Implementaci\u00f3n con Multipass y K3sup","text":"<p>Esta seccion utilizo la imagen Ubuntu 22.04 LTS y ademas ya cuenta con cgroupv2. Pero por defecto, un usuario sin privilegios solo puede obtener el controlador de memoria y el controlador de pids delegados. Para permitir la delegaci\u00f3n de otros controladores como cpu, cpuset y io, ejecuta los siguientes comandos dentro de nuestra instancia:</p> <pre><code>$ sudo mkdir -p /etc/systemd/system/user@.service.d\n$ cat &lt;&lt;EOF | sudo tee /etc/systemd/system/user@.service.d/delegate.conf\n[Service]\nDelegate=cpu cpuset io memory pids\nEOF\n$ sudo systemctl daemon-reload\n</code></pre> <p>Reiniciamos la instancia y procemos a instalar k3s-rootless</p> <pre><code># Detenemos el servicio de k3s en Servidor e instalamos uidmap\n$ sudo systemctl stop k3s\n$ sudo apt install uidmap\n\n# Instalacion del k3s-rootless.service\n$ mkdir -p .config/systemd/user\n$ cd .config/systemd/user/\n$ curl https://raw.githubusercontent.com/k3s-io/k3s/master/k3s-rootless.service -o k3s-rootless.service\n$ systemctl --user daemon-reload\n$ systemctl --user enable --now k3s-rootless\n\n# Comprobamos el funcionamiento\n$ KUBECONFIG=~/.kube/k3s.yaml kubectl get pods -A\n\n# Observacion de logs\n$ journalctl --user -f -u k3s-rootless\n</code></pre>"},{"location":"seguridad/seguridad/#3-vulnerabilidades-en-la-cadena-de-aprovisionamiento","title":"3. Vulnerabilidades en la Cadena de Aprovisionamiento","text":"<p>Los contenedores adoptan muchas formas en diferentes fases del ciclo de vida de la cadena de suministro del desarrollo; cada una de ellas presenta desaf\u00edos de seguridad \u00fanicos. Un solo contenedor puede depender de cientos de componentes y dependencias de terceros, lo que hace que la confianza en el origen en cada fase sea extremadamente dif\u00edcil. Estos desaf\u00edos incluyen, pero no se limitan a, la integridad de la imagen, la composici\u00f3n de la imagen y las vulnerabilidades de software conocidas.</p>"},{"location":"seguridad/seguridad/#aspectos-a-tener-en-cuenta","title":"Aspectos a tener en cuenta","text":"<ul> <li>Integridad de la Imagen: La procedencia del software ha atra\u00eddo recientemente una atenci\u00f3n significativa en los medios debido a eventos como la brecha de SolarWinds y una variedad de paquetes de terceros comprometidos. Estos riesgos de la cadena de suministro pueden surgir en varias etapas del ciclo de construcci\u00f3n del contenedor, as\u00ed como en tiempo de ejecuci\u00f3n dentro de Kubernetes. Cuando no existen sistemas de registro respecto a los contenidos de una imagen de contenedor, es posible que un contenedor inesperado se ejecute en un cl\u00faster.</li> <li>Composici\u00f3n de la Imagen: Una imagen de contenedor consta de capas, cada una de las cuales puede presentar implicaciones de seguridad. Una imagen de contenedor bien construida no solo reduce la superficie de ataque, sino que tambi\u00e9n puede aumentar la eficiencia de la implementaci\u00f3n. Las im\u00e1genes con software innecesario pueden ser utilizadas para elevar privilegios o explotar vulnerabilidades conocidas.</li> <li>Vulnerabilidades de Software Conocidas: Debido a su uso extensivo de paquetes de terceros, muchas im\u00e1genes de contenedores son inherentemente peligrosas para ser incorporadas en un entorno de confianza y ejecutadas. Por ejemplo, si una capa en una imagen contiene una versi\u00f3n de OpenSSL susceptible a una explotaci\u00f3n conocida, esta puede propagarse a varias cargas de trabajo y, sin saberlo, poner en riesgo todo un cl\u00faster.</li> </ul>"},{"location":"seguridad/seguridad/#grype","title":"Grype","text":"<p>Existen muchas herramientas en el mercado (tanto comerciales como de c\u00f3digo abierto) que ofrecen escaneo de vulnerabilidades. Recientemente, encontr\u00e9 una herramienta de escaneo de vulnerabilidades muy ligera y ordenada, llamada Grype, gestionada por Anchore.</p> <p>Grype permite identificar y reportar vulnerabilidades conocidas en im\u00e1genes de contenedores, directorios y archivos individuales. Es particularmente \u00fatil para desarrolladores y equipos de seguridad que buscan asegurar sus aplicaciones y entornos de despliegue.</p>"},{"location":"seguridad/seguridad/#instalacion","title":"Instalaci\u00f3n","text":"<p>Para instalar grype, alcanza con ejecutar y descargar el binario</p> <pre><code>curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sudo sh -s -- -b /usr/local/bin\n</code></pre>"},{"location":"seguridad/seguridad/#uso","title":"Uso","text":"<p>Grype puede escanear imagenes provenientes de multiples fuentes ademas de Docker</p> <pre><code># Escanea un archivo de imagen de contenedor(proveniente de `docker image save ...`, `podman save ...`)\ngrype path/to/image.tar\n\n# Escanea un directorio\ngrype dir:path/to/dir\n\n# Ejemplo: Escanea la ultima imagen de Grafana disponible\ngrype docker:grafana/grafana:latest  \n</code></pre>"}]}